{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "\n",
    "from nameparser import HumanName\n",
    "from pymarc import MARCReader\n",
    "from titlecase import titlecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_uid(record):\n",
    "    return record.get_fields('001')[0].value().replace('AAI','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unrestricteds_filepath = 'source_data/ProquestDissertations/UnrestrictedTheses'\n",
    "\n",
    "with open(os.path.join(unrestricteds_filepath, 'MARCDATA.MRC'), 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    marc_unrestricted_records = list()\n",
    "    for record in reader:\n",
    "        marc_unrestricted_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restricteds_filepath = 'source_data/ProquestDissertations/RestrictedTheses'\n",
    "\n",
    "with open(os.path.join(restricteds_filepath, 'MARCDATA.MRC'), 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    marc_restricted_records = list()\n",
    "    for record in reader:\n",
    "        marc_restricted_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_filepath= 'source_data/Image_Discs_and_Supplement_Files'\n",
    "\n",
    "with open(os.path.join(images_filepath, 'MARCDATA.MRC'), 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    marc_images_records = list()\n",
    "    for record in reader:\n",
    "        marc_images_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marc_all_records = {i for i in marc_restricted_records}.union(\n",
    "                    {i for i in marc_unrestricted_records}.union(\n",
    "                     {i for i in marc_images_records}))\n",
    "\n",
    "marc_unrestricted_uids = {lookup_uid(i) for i in marc_unrestricted_records}\n",
    "marc_restricted_uids = {lookup_uid(i) for i in marc_restricted_records}\n",
    "marc_images_uids = {lookup_uid(i) for i in marc_images_records}\n",
    "marc_all_uids = {lookup_uid(record) for record in marc_all_records}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_spreadsheets = [os.path.join(root, file)\n",
    "                    for root, dirs, files in os.walk('source_data/Image_Discs_and_Supplement_Files/')\n",
    "                    for file in files\n",
    "                    if os.path.splitext(file)[1] == '.xlsx']\n",
    "\n",
    "nicks_files = {'a': 'source_data/Image_Discs_and_Supplement_Files/PubNames.xlsx',\n",
    "               'b': 'source_data/Image_Discs_and_Supplement_Files/DAAP_probably_not_yet_DigitalCommons_uploaded.xlsx',\n",
    "               'c': 'source_data/Image_Discs_and_Supplement_Files/Masters_Theses_French-Cajun_LA_au-permissions.xlsx',\n",
    "               'd': 'source_data/Legacy name mainframe query blank depts.xlsx',\n",
    "               'e': 'source_data/Legacy name mainframe query existing depts.xlsx',\n",
    "#                'f': '/home/francis/Downloads/gradschool_disstheses_1.xls_Wed_Apr_19_12_11_52_2017part_1.xlsx',\n",
    "              }\n",
    "\n",
    "def nick_of_file(filename):\n",
    "    for nick, file in nicks_files.items():\n",
    "        if filename == file:\n",
    "            return nick\n",
    "\n",
    "def parse_workbook(file):\n",
    "    wb_dict = dict()\n",
    "    print(file)\n",
    "    wb = openpyxl.load_workbook(file)\n",
    "    for sheetname in wb.sheetnames:\n",
    "        current_sheet = wb.get_sheet_by_name(sheetname)\n",
    "        sheet_dict = dict()\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                keys = [i.value or num for i in row]\n",
    "                continue\n",
    "            values = [i.value for i in row]\n",
    "            row_dict = {keys[i]: values[i] for i in range(len(keys))}\n",
    "            sheet_dict[num] = row_dict\n",
    "        wb_dict[sheetname] = sheet_dict\n",
    "    return wb_dict\n",
    "\n",
    "all_odds_dict = dict()\n",
    "for nick, file in nicks_files.items():\n",
    "    filename = os.path.split(file)[1]\n",
    "    all_odds_dict[nick] = parse_workbook(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duplicates_filepath = '/media/francis/U/ProquestDissertations/Theses_and_Dissertations/ProquestDissertations/ETDDuplicates'\n",
    "restricteds_filepath = '/media/francis/U/ProquestDissertations/Theses_and_Dissertations/ProquestDissertations/RestrictedTheses/'\n",
    "unrestricteds_filepath = '/media/francis/U/ProquestDissertations/Theses_and_Dissertations/ProquestDissertations/UnrestrictedTheses/'\n",
    "folder_images = '/media/francis/U/ProquestDissertations/Theses_and_Dissertations/Image Discs and Supplement Files/'\n",
    "\n",
    "folder_restricted = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(restricteds_filepath)\n",
    "                    if file.replace('.pdf', '').isnumeric()}\n",
    "folder_unrestricted = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(unrestricteds_filepath)\n",
    "                    if file.replace('.pdf', '').isnumeric()}\n",
    "folder_duplicated = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(duplicates_filepath)\n",
    "                    if file.replace('.pdf', '').isnumeric()}\n",
    "folder_images = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(images_filepath)\n",
    "                    if os.path.splitext(file)[1].lower() == '.pdf'}\n",
    "folder_all = folder_restricted.union(folder_unrestricted).union(folder_duplicated).union(folder_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('expected:', 'pass', len(marc_unrestricted_uids), 'pass', len(marc_restricted_uids), len(marc_images_records))\n",
    "print('observed:', len(folder_all), len(folder_unrestricted), len(folder_duplicated), len(folder_restricted), len(folder_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding disciplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = openpyxl.load_workbook('../ETD_to_DigitalCommons/data/Disciplines for imported documents revised for errors.xlsx')\n",
    "matches_sheet = matches.get_sheet_by_name('Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches_dict = set()\n",
    "for num, row in enumerate(matches_sheet.iter_rows()):\n",
    "    if num == 0:\n",
    "        headers = (i.value.replace(' ', '') for i in row)\n",
    "        Matches = namedtuple('Matches', headers)\n",
    "        continue\n",
    "    values = (i.value for i in row)\n",
    "    item = Matches(*values)\n",
    "    matches_dict.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_discipline(obs_dept, obs_degree):\n",
    "    for item in matches_dict:\n",
    "        dept, degree, discipline = item.Ifdepartmentequals, item.anddegree_nameequals, item.thendisciplinesis\n",
    "        if obs_dept == dept:\n",
    "            if degree and obs_degree == degree:\n",
    "                return discipline\n",
    "            if not degree:\n",
    "                return discipline\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_S3_url(uid):\n",
    "    return 'https://s3-us-west-2.amazonaws.com/setq-digitalcommons/{}.pdf'.format(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_clean_title(record):\n",
    "    text = record.get_fields('245')[0].value()\n",
    "    return clean_title(text)\n",
    "    \n",
    "def clean_title(text):\n",
    "    text = titlecase(text)\n",
    "    text = text.replace(':  ', \": \")\n",
    "    for k, v in wrong_roman_numeral.items():\n",
    "        if k in text:\n",
    "            text = text.replace(k, v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_roman_numeral = {' Ii': ' II',\n",
    "                       ' Iii ': ' III ',\n",
    "                       '-Iii': '-III',\n",
    "                       ' Iii.': ' III.',\n",
    "                       ' Iv ': ' IV ',\n",
    "                       ' Vi ': ' VI ',\n",
    "                       ' Iv.': ' IV.',\n",
    "                       ' Iv)': 'IV)',\n",
    "                       ' Viii': ' VIII',\n",
    "                       '-Vii ': '-VII',\n",
    "                       '-Viii': '-VIII',\n",
    "                       ' Vii': ' VII',\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abbr_degree = {\"MPT\": \"Master of Physical Therapy (MPT)\",\n",
    "    \"MUP\": \"Master of Urban Planning (MUP)\",\n",
    "    \"DM\": \"Doctor of Music (DM)\",\n",
    "    \"MTS\": \"Master of Theological Studies (MTS)\",\n",
    "    \"AuD\": \"Doctor of Audiology (AuD)\",\n",
    "    \"MSEE\": \"Master of Science in Electrical Engineering (MSEE)\",\n",
    "    \"MSIB\": \"Master of Science in International Business (MSIB)\",\n",
    "    \"MCSM\": \"Master of Construction Science and Management (MCSM)\",\n",
    "    \"PsyD\": \"Doctor of Psychology (PsyD)\",\n",
    "    \"MSEM\": \"Master of Science in Engineering Management (MSEM)\",\n",
    "    \"MSMSE\": \"Master of Science in Materials Science and Engineering (MSMSE)\",\n",
    "    \"RhD\": \"Doctor of Rehabilitation (RhD)\",\n",
    "    \"MATE\": \"Master of Arts in the Teaching of English (MATE)\",\n",
    "    \"DPT\": \"Doctor of Physical Therapy (DPT)\",\n",
    "    \"MSAgE\": \"Master of Science in Agricultural Engineering (MSAgE)\",\n",
    "    \"PhDOtol\": \"PhD Otolaryngology (PhDOtol)\",\n",
    "    \"MSHRM\": \"Master of Science in Human Resources Management (MSHRM)\",\n",
    "    \"MIM\": \"Master of International Management (MIM)\",\n",
    "    \"DMin\": \"Doctor of Ministry (DMin)\",\n",
    "    \"MSIE\": \"Master of Science in Industrial Engineering (MSIE)\",\n",
    "    \"MSISE\": \"Master of Science in Infrastructure Systems Engineering (MSISE)\",\n",
    "    \"DPA\": \"Doctor of Public Administration (DPA)\",\n",
    "    \"HSOP\": \"Doctor of Philosophy in Health Services Research (HSOP)\",\n",
    "    \"MMatSE\": \"Master of Materials Science and Engineering (MMatSE)\",\n",
    "    \"MAeroE\": \"Master of Aeronautical Engineering (MAeroE)\",\n",
    "    \"MMT\": \"Master in Management of Technology (MMT)\",\n",
    "    \"MSJ\": \"Master of Science in Jurisprudence (MSJ)\",\n",
    "    \"MHP\": \"Master of Historic Preservation (MHP)\",\n",
    "    \"DEng\": \"Doctor of Engineering (DEng)\",\n",
    "    \"MBA\": \"Master of Business Administration (MBA)\",\n",
    "    \"MRED\": \"Master of Real Estate Development (MRED)\",\n",
    "    \"MCTE\": \"Master of Career and Technology Education (MCTE)\",\n",
    "    \"MSAeroE\": \"Master of Science in Aerospace Engineering (MSAeroE)\",\n",
    "    \"MAR\": \"Master of Arts in Religion (MAR)\",\n",
    "    \"MST\": \"Master's of Science in Teaching (MST)\",\n",
    "    \"MJS\": \"Master of Judicial Studies (MJS)\",\n",
    "    \"MALA\": \"Master of Arts in Liberal Arts (MALA)\",\n",
    "    \"MSETM\": \"Master of Science in Environmental Technology Management (MSETM)\",\n",
    "    \"MSHTM\": \"Master of Science in Hospitality and Tourism Management (MSHTM)\",\n",
    "    \"Th.M\": \"Master of Theology (Th.M)\",\n",
    "    \"MSM\": \"Master of Science in Management (MSM)\",\n",
    "    \"MCRP\": \"Master of City and Regional Planning (MCRP)\",\n",
    "    \"MBS\": \"Master of Building Science (MBS)\",\n",
    "    \"MAIS\": \"Master of Arts in Interdisciplinary Studies (MAIS)\",\n",
    "    \"DBA\": \"Doctor of Business Administration (DBA)\",\n",
    "    \"MPH\": \"Master of Public Health (MPH)\",\n",
    "    \"MIDS\": \"Master of Interdisciplinary Studies (MIDS)\",\n",
    "    \"MPA/JD\": \"Master of Public Administration/Juris Doctorate (MPA/JD)\",\n",
    "    \"PhD\": \"Doctor of Philosophy (PhD)\",\n",
    "    \"DMgt\": \"Doctor of Management (DMgt)\",\n",
    "    \"MCIS\": \"Master of Computer and Information Science (MCIS)\",\n",
    "    \"MAE\": \"Master of Arts in Education (MAE)\",\n",
    "    \"MHD\": \"Master of Human Development (MHD)\",\n",
    "    \"MM\": \"Master of Music (MM)\",\n",
    "    \"MGS\": \"Master of General Studies (MGS)\",\n",
    "    \"MSN\": \"Master of Science in Nursing (MSN)\",\n",
    "    \"M.Div\": \"Master of Divinity (M.Div)\",\n",
    "    \"MAC\": \"Master of Arts in Counseling (MAC)\",\n",
    "    \"MCJ\": \"Master of Criminal Justice (MCJ)\",\n",
    "    \"MFR\": \"Master of Forest Resources (MFR)\",\n",
    "    \"MSSS\": \"Master of Science in Computer Science (MSCS)\",\n",
    "    \"MSA\": \"Master of Science in Administration (MSA)\",\n",
    "    \"MURP\": \"Master of Urban and Regional Planning (MURP)\",\n",
    "    \"MAS\": \"Master in Advanced Studies (MAS)\",\n",
    "    \"ND\": \"Doctor of Nursing (ND)\",\n",
    "    \"ME\": \"Master of Engineering (ME)\",\n",
    "    \"MSCRP\": \"Master of Science in Community and Regional Planning (MSCRP)\",\n",
    "    \"MArch\": \"Master of Architecture (MArch)\",\n",
    "    \"MLIS\": \"Master of Library and Information Science (MLIS)\",\n",
    "    \"MSOtol\": \"MS Otolaryngology (MSOtol)\",\n",
    "    \"MLS\": \"Master of Library Science/Master of Life Sciences (MLS)\",\n",
    "    \"MSMANFE\": \"Master of Science in Manufacturing Engineering (MSMANFE)\",\n",
    "    \"MSSE\": \"Master of Science and Software Engineering (MSSE)\",\n",
    "    \"MEngr\": \"Master of Engineering (MEngr)\",\n",
    "    \"MSB\": \"Masters of Science in Bioscience (MSB)\",\n",
    "    \"PED\": \"Doctor of Physical Education (PED)\",\n",
    "    \"MFA\": \"Master of Fine Arts (MFA)\",\n",
    "    \"MMC\": \"Master of Mass Communication (MMC)\",\n",
    "    \"MSBAE\": \"Master of Science in Biological and Agricultural Engineering (MSBAE)\",\n",
    "    \"MAgEd\": \"Master of Agricultural Education (MAgEd)\",\n",
    "    \"MSECE\": \"Master of Science in Electrical and Computer Engineering (MSECE)\",\n",
    "    \"DMD\": \"Doctor of Dental Medicine (DMD)\",\n",
    "    \"MSMatSE\": \"Master of Science in Material Science Engineering (MSMatSE)\",\n",
    "    \"MAPC\": \"Master of Arts in Pastoral Counseling (MAPC)\",\n",
    "    \"MSEd\": \"Master of Science in Education (MSEd)\",\n",
    "    \"DPDS\": \"Doctor of Planning and Development Studies (DPDS)\",\n",
    "    \"MRP\": \"Master of Regional Planning (MRP)\",\n",
    "    \"MNS\": \"Master of Natural Sciences (MNS)\",\n",
    "    \"EdD\": \"Doctor of Education (EdD)\",\n",
    "    \"DrPH\": \"Doctor of Public Health (DrPH)\",\n",
    "    \"DNS\": \"Doctor of Nursing Science (DNS)\",\n",
    "    \"MSIEOR\": \"Master of Science in Industrial Engineering and Operations Research (MSIEOR)\",\n",
    "    \"MAT\": \"Master of Arts in Teaching (MAT)\",\n",
    "    \"MEE\": \"Master of Electrical Engineering (MEE)\",\n",
    "    \"MS\": \"Master of Science (MS)\",\n",
    "    \"MSECO\": \"Master of Science in Economics (MSECO)\",\n",
    "    \"MLA\": \"Master of Landscape Architecture (MLA)\",\n",
    "    \"PhDSurg\": \"PhD Surgergy (PhDSurg)\",\n",
    "    \"MSES\": \"Master of Science in Engineering Science (MSES)\",\n",
    "    \"MHI\": \"Masters of Health Informatics (MHI)\",\n",
    "    \"MSME\": \"Master of Science in Mechanical Engineering (MSME)\",\n",
    "    \"MMUS\": \"Master of Music (MMUS)\",\n",
    "    \"MSW\": \"Master of Social Work (MSW)\",\n",
    "    \"MME\": \"Master of Music Education (MME)\",\n",
    "    \"DMA\": \"Doctor of Musical Arts (DMA)\",\n",
    "    \"MPA\": \"Master of Public Administration (MPA)\",\n",
    "    \"DA\": \"Doctor of Arts (DA)\",\n",
    "    \"MApStat\": \"Master of Applied Statistics (MApStat)\",\n",
    "    \"MSP\": \"Master of Science in Planning (MSP)\",\n",
    "    \"MPP\": \"Master of Public Policy (MPP)\",\n",
    "    \"MSExpSurg\": \"Medical Surgeon in Experimental Surgery (MSExpSurg)\",\n",
    "    \"EdS\": \"Education Specialist (EdS)\",\n",
    "    \"MF\": \"Master of Forestry (MF)\",\n",
    "    \"MPlan\": \"Master of Planning (MPlan)\",\n",
    "    \"MBT\": \"Master of Business Taxation (MBT)\",\n",
    "    \"HSD\": \"Doctor of Health and Safety (HSD)\",\n",
    "    \"MHRD\": \"Master of Human Resource Development (MHRD)\",\n",
    "    \"MSPH\": \"Master of Science in Public Health (MSPH)\",\n",
    "    \"MChE\": \"Master of Chemical Engineering (MChE)\",\n",
    "    \"MSPE\": \"Master of Science in Petroleum Engineering (MSPE)\",\n",
    "    \"MCompE\": \"Master of Computer Engineering (MCompE)\",\n",
    "    \"MT\": \"Master in Taxation (MT)\",\n",
    "    \"MAcc\": \"Master of Accounting (MAcc)\",\n",
    "    \"MPM\": \"Master of Public Management (MPM)\",\n",
    "    \"MSE\": \"Master of Science in Engineering (MSE)\",\n",
    "    \"DME\": \"Doctor of Music Education (DME)\",\n",
    "    \"DSW\": \"Doctor of Social Work (DSW)\",\n",
    "    \"MSCE\": \"Master of Science in Civil Engineering (MSCE)\",\n",
    "    \"DVM\": \"Doctor of Veterinary Medicine (DVM)\",\n",
    "    \"MCE\": \"Master of Civil Engineering (MCE)\",\n",
    "    \"MES\": \"Master of Environmental Studies (MES)\",\n",
    "    \"MECom\": \"Master of Electronic Commerce (MECom)\",\n",
    "    \"MHA\": \"Master of Health Administration (MHA)\",\n",
    "    \"PharmD\": \"Doctor of Pharmacy (PharmD)\",\n",
    "    \"MA\": \"Master of Arts (MA)\",\n",
    "    \"Ded\": \"Doctor of Education (Ded)\",\n",
    "    \"MEnvE\": \"Master of Environmental Engineering (MEnvE)\",\n",
    "    \"ReD\": \"Doctor of Recreation (ReD)\",\n",
    "    \"JD\": \"Juris Doctorate (JD)\",\n",
    "    \"MSBiosyAgE\": \"Master of Science in Biosystems and Agricultural Engineering (MSBiosyAgE)\",\n",
    "    \"PMBA\": \"Professional Master of Business Administration (PMBA)\",\n",
    "    \"MHAMS\": \"Master of Historical Administration and Museum Studies (MHAMS)\",\n",
    "    \"MSIS\": \"Master of Science in Interdisciplinary Studies (MSIS)\",\n",
    "    \"IMES\": \"International Master of Environmental Sciences (IMES)\",\n",
    "    \"MSChE\": \"Master of Science in Chemical Engineering (MSChE)\",\n",
    "    \"MPAcc\": \"Master of Professional Accounting (MPAcc)\",\n",
    "    \"MGIS\": \"Master of Geographic Information Science (MGIS)\",\n",
    "    \"MBioSci\": \"Master of Biological Science (MBioSci)\",\n",
    "    \"MCM\": \"Master of Construction Management (MCM)\",\n",
    "    \"MSMS\": \"Master of Science in Medical Sciences (MSMS)\",\n",
    "    \"MD\": \"Medical Doctor (MD)\",\n",
    "    \"Medical Science\": \"Doctor of Philosophy (Medical Science)\",\n",
    "    \"MGeoE\": \"Master of Geomechanics Engineering (MGeoE)\",\n",
    "    \"MEd\": \"Master of Education (MEd)\",\n",
    "    \"MAM\": \"Master in Agricultural Management (MAM)\",\n",
    "    \"MPRTM\": \"Master of Parks, Recreation and Tourism Management (MPRTM)\",\n",
    "    \"MAgr\": \"Master of Agriculture (MAgr)\",\n",
    "    \"POCS\": \"Doctor of Oceanography and Coastal Sciences (POCS)\",\n",
    "    \"PVMPB\": \"Doctor of Biomedical and Veterinary Medical Sciences-Pathobiological Sciences (PVMPB)\",\n",
    "    \"PNFS\": \"Doctor of Nutrition and Food Sciences (PNFS)\",\n",
    "    \"PENTM\": \"Doctor of Entomology (PENTM)\",\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# non_matching_degree_abbrevs = dict()\n",
    "# def expand_degree_type(degree_name):\n",
    "#     if degree_name in abbr_degree:\n",
    "#         return abbr_degree[degree_name]\n",
    "#     else:\n",
    "#         if degree_name not in non_matching_degree_abbrevs:\n",
    "#             non_matching_degree_abbrevs[degree_name] = []\n",
    "            \n",
    "# for record in ori:\n",
    "#     stated_degree = record.get_fields('791')[0].value()\n",
    "#     stated_degree = stated_degree.replace('.', '')\n",
    "#     if stated_degree in first_conversion:\n",
    "#         stated_degree = first_conversion[stated_degree]\n",
    "#     if stated_degree not in abbr_degree:\n",
    "#         print(lookup_uid(record))\n",
    "# #         print(stated_degree, record.get_fields('856')[0].value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_conversion = {'EducatD': 'EdD',\n",
    "                    'DED': 'EdD',\n",
    "                    'DMus': 'DMA',\n",
    "                    'OCS': 'POCS',\n",
    "                    'VetMedSc': 'PVMPB',\n",
    "                    'DrSciEng': 'PNFS',\n",
    "                    'SCDC': 'PENTM'}\n",
    "\n",
    "def match_degrees(record):\n",
    "    stated_degree = record.get_fields('791')[0].value()\n",
    "    if not stated_degree:\n",
    "        return ''\n",
    "    alph_degree = stated_degree.replace('.','')\n",
    "    if alph_degree in first_conversion:\n",
    "        alph_degree = first_conversion[alph_degree]\n",
    "    if alph_degree in abbr_degree:\n",
    "        return abbr_degree[alph_degree]\n",
    "    else:\n",
    "        return 'not yet implemented'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpret_directors(record):\n",
    "    text_a, text_b = parse_500(record)\n",
    "    return split_directors(text_b)\n",
    "\n",
    "def parse_500(record):\n",
    "    value_500 = [i.value() for i in record.get_fields('500')]\n",
    "    if len(value_500) == 1:\n",
    "        return value_500[0], ''\n",
    "    else:\n",
    "        return value_500[0], value_500[1]  \n",
    "\n",
    "def split_directors(text_b):\n",
    "    directors_list = parse_advisors_field(text_b)\n",
    "    if directors_list:\n",
    "        if len(directors_list) == 3:\n",
    "            return directors_list[0], directors_list[1], directors_list[2]\n",
    "        elif len(directors_list) == 2:\n",
    "            return directors_list[0], directors_list[1], ''\n",
    "        elif len(directors_list) == 1:\n",
    "            return directors_list[0], '', ''\n",
    "    return ('', '', '')\n",
    "\n",
    "def parse_advisors_field(text):\n",
    "    for title in ('Directors: ',\n",
    "                  'Director: ',\n",
    "                  'Co-Chairs: ',\n",
    "                  'Co-chairs: ',\n",
    "                  'Co-Chairmen: ',\n",
    "                  'Adviser: ',\n",
    "                  'Advisers: ',\n",
    "                  'Chair: ',\n",
    "                  'Directed: '):\n",
    "        if title in text:\n",
    "            text = text.replace(title, '')\n",
    "            text = text\n",
    "            text = unperiod(text)\n",
    "            if text:\n",
    "                return [i.strip() for i in text.split('; ')]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def unperiod(text):\n",
    "    if text[-1] == '.':\n",
    "        return text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_source(record):\n",
    "    fields = [i.value() for i in record.get_fields('500') if 'Source' in i.value()][0]\n",
    "    fields = unperiod(fields)\n",
    "    fields = fields.replace('Source: ', '')\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_520(record):\n",
    "    list_520 = [i for i in record.get_fields('520')]\n",
    "    if list_520:\n",
    "        combined_text = ' '.join([i.value() for i in list_520])\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    if combined_text == 'Abstract not available.':\n",
    "        combined_text = ''\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_650(record):\n",
    "    value_650 = [i.value() for i in record.get_fields('650')]\n",
    "    value_650 = [i.capitalize().replace('.', '') for i in value_650]\n",
    "    if value_650:\n",
    "        combined_text = '; '.join(value_650)\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_author_names(record):\n",
    "    name_clump = record.get_fields('100')[0].value()\n",
    "    name_clump = unperiod(name_clump)\n",
    "    name = HumanName(name_clump)\n",
    "    last_name = name.last\n",
    "    middle_name = name.middle\n",
    "    suffix = name.suffix\n",
    "    suffix = standardize_suffix(suffix)\n",
    "    if name.nickname:\n",
    "        first_name = \"{} {}\".format(name.first, name.nickname)\n",
    "    else:\n",
    "        first_name = name.first\n",
    "    return first_name.capitalize(), middle_name.capitalize(), last_name.capitalize(), suffix\n",
    "\n",
    "def standardize_suffix(text):\n",
    "    replace_dict = {'JR': 'Jr', 'SR': 'Sr', '3RD': 'III', 'ED': 'Ed.'}\n",
    "    for wrong in replace_dict:\n",
    "        if wrong in text:\n",
    "            text = text.replace(wrong, replace_dict[wrong])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_institution_department(record, kind='legacy'):\n",
    "    if record in marc_restricted_records or record in marc_unrestricted_records:\n",
    "        return (lookup_inst(record), '')\n",
    "    elif record in marc_images_records:\n",
    "        inst = 'Louisiana State University and Agricultural & Mechanical College'\n",
    "        dept = lookup_inst(record).replace('Louisiana State University and Agricultural & Mechanical College', '')\n",
    "        if dept[:2] == '. ':\n",
    "            dept = dept[2:]\n",
    "        if kind == 'current':\n",
    "            possible_revised_dept = lookup_current_dept(dept)\n",
    "            if possible_revised_dept:\n",
    "                dept = possible_revised_dept\n",
    "        return (inst, dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overlooked_degrees = set()\n",
    "\n",
    "def read_legacy_dept_map():\n",
    "    legacy_current = dict()\n",
    "    sourcepath = '../ETD_to_DigitalCommons/data/LegacyNames.csv'\n",
    "    with open(sourcepath, encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for num, row in enumerate(csvreader):\n",
    "            if num == 0:\n",
    "                headers = (i for i in row)\n",
    "                continue\n",
    "            current, legacy = row[0].strip(), row[1].strip()\n",
    "            if current and current != 'Program no longer active':\n",
    "                if legacy not in legacy_current:\n",
    "                    if legacy not in ('New', ):\n",
    "                        legacy_current[legacy] = current\n",
    "                else:\n",
    "                    print(legacy, 'has two mappings')\n",
    "    return legacy_current\n",
    "\n",
    "legacy_current = read_legacy_dept_map()\n",
    "def lookup_current_dept(legacy_dept):\n",
    "    if legacy_dept in legacy_current:\n",
    "        return legacy_current[legacy_dept]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_inst(record):\n",
    "    text = record.get_fields('710')[0].value()\n",
    "    text = unperiod(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_isbn(record):\n",
    "    if record.get_fields('020'):\n",
    "        return record.get_fields('020')[0].value()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_dtype(record):\n",
    "    for degree in ('PhD', 'DMA', 'EdD', 'DBA', 'PENTM', 'PNFS', 'PVMPB', 'POCS' ):\n",
    "        if degree in match_degrees(record):\n",
    "            return \"dissertation\"\n",
    "    return \"thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def armageddon_if_restricted(record):\n",
    "    if record in marc_restricted_records:\n",
    "        return \"9999-12-01\"\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_restricted(record):\n",
    "    if record in marc_restricted_records:\n",
    "        return 'withheld'\n",
    "    elif record in marc_images_records:\n",
    "        return lookup_odd_permissions(record)\n",
    "    return 'unrestricted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_odd_permissions(record):\n",
    "    uids_permissions = {v['PQ_Number']: v['Permissions']\n",
    "                        for k, v in all_odds_dict['c']['Sheet1'].items()}\n",
    "    if uids_permissions.get(lookup_uid(record)) == 'denied':\n",
    "        return 'withheld'\n",
    "    return 'unrestricted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_mtfc_field_by_uid(uid, field):\n",
    "    for k, v in all_odds_dict['c']['Sheet1'].items():\n",
    "        if v['PQ_Number'] == uid:\n",
    "            sought_value = v.get(field, '')\n",
    "            if sought_value == 'none':\n",
    "                return ''\n",
    "            return sought_value\n",
    "    return ''\n",
    "\n",
    "def lookup_DAAP_frompaper_by_uid(uid, field):\n",
    "    for k, v in all_odds_dict['b']['DigitizeFromPaper'].items():\n",
    "        if v['PQ_Dig_Num'] == uid:\n",
    "            return v.get(field, '')\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fieldnames_values(record):\n",
    "    uid = lookup_uid(record)\n",
    "    fieldnames_values = (('uid', uid),\n",
    "                         ('title', lookup_clean_title(record)),\n",
    "                         ('fulltext_url', make_S3_url(uid)),\n",
    "                         ('keywords', combine_650(record)),\n",
    "                         ('abstract', combine_520(record)),\n",
    "                         ('author1_fname', parse_author_names(record)[0]),\n",
    "                         ('author1_mname', parse_author_names(record)[1]),\n",
    "                         ('author1_lname', parse_author_names(record)[2]),\n",
    "                         ('author1_suffix', parse_author_names(record)[3]),\n",
    "                         ('author1_email', ''),\n",
    "                         ('author1_institution', split_institution_department(record)[0]),\n",
    "                         ('advisor1', interpret_directors(record)[0]),\n",
    "                         ('advisor2', interpret_directors(record)[1]),\n",
    "                         ('advisor3', interpret_directors(record)[2]),\n",
    "                         ('availability', is_restricted(record)),\n",
    "                         ('availability_description', ''),\n",
    "                         ('comments', ''),\n",
    "                         ('degree_name', match_degrees(record)),\n",
    "                         ('department', split_institution_department(record, 'current')[1]),\n",
    "                         ('legacy_department', split_institution_department(record, 'legacy')[1]),\n",
    "                         ('disciplines', match_discipline(split_institution_department(record, 'current')[1],\n",
    "                                                          match_degrees(record))),\n",
    "                         ('document_type', determine_dtype(record)),\n",
    "                         ('embargo_date', armageddon_if_restricted(record)),\n",
    "                         ('publication_date', record.get_fields('792')[0].value()),\n",
    "                         ('season', ''),\n",
    "                         ('release_date', ''),\n",
    "                         ('isbn', lookup_isbn(record)),\n",
    "                         ('pagelength', record.get_fields('300')[0].value().replace(' p.', '')),\n",
    "                         ('source', find_source(record)),\n",
    "                         ('diss_note', unperiod(record.get_fields('502')[0].value())),\n",
    "                         ('host_item', unperiod(record.get_fields('773')[0].value())),\n",
    "                         ('language', record.get_fields('793')[0].value()),\n",
    "#                          ('host_url', record.get_fields('856')[0].value()),\n",
    "                         ('alternate_uid', lookup_DAAP_frompaper_by_uid(uid, 'Pub_Num')),\n",
    "                         ('middleton_call_number', lookup_mtfc_field_by_uid(uid, 'MIDL-MAIN_CALL_NO')),\n",
    "                         ('middleton_location', lookup_mtfc_field_by_uid(uid, 'MIDL-MAIN_LOCATION')),\n",
    "                         ('docs_micro_call_number', lookup_mtfc_field_by_uid(uid, 'DOCS_MICRO_CALL NO.')),\n",
    "                         ('docs_micro_location', lookup_mtfc_field_by_uid(uid, 'DOCS_MICRO_LOCATION')),\n",
    "                         ('specials_call_number', lookup_mtfc_field_by_uid(uid, 'SPEC_COLL_CALL_NO')),\n",
    "                         ('specials_location', lookup_mtfc_field_by_uid(uid, 'SPEC_COLL_LOCATION')),\n",
    "                        )\n",
    "    return fieldnames_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_csv(records_list, output_folder, output_filename):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for num, record in enumerate(records_list):\n",
    "        if num == 0:\n",
    "            csv_as_list_of_lists = [[fieldname for fieldname, value in make_fieldnames_values(record)], ]\n",
    "        record_values = [value for fieldname, value in make_fieldnames_values(record)]\n",
    "        csv_as_list_of_lists.append(record_values)\n",
    "    csv_writer(csv_as_list_of_lists, os.path.join(output_folder, output_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_filename = 'draft_SetQ.csv'\n",
    "output_folder = '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output'\n",
    "\n",
    "build_csv(marc_images_records, output_folder, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print a full record matching a specified uid\n",
    "\n",
    "def find_print_record(uid):\n",
    "    for record in marc_all_records:\n",
    "        if lookup_uid(record) == uid:\n",
    "            return record.as_dict()\n",
    "        \n",
    "find_print_record('DP69258')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# an example of one record\n",
    "\n",
    "to_do_records = marc_images_records\n",
    "\n",
    "# marc_images_records[0].as_dict()\n",
    "find_print_record('DP69224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show all unique values for field 650\n",
    "\n",
    "all_650a = set()\n",
    "for record in to_do_records:\n",
    "    for i in record.get_fields('710'):\n",
    "        all_650a.add(i.value().replace('Louisiana State University and Agricultural & Mechanical College. ', ''))\n",
    "#     all_650a.add(record.get_fields('710')[0].value())\n",
    "print(sorted(all_650a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do any field values have an @ in it?\n",
    "\n",
    "for record in to_do_records:\n",
    "    all_fields = [i.value() for i in record.get_fields()]\n",
    "    for text in all_fields:\n",
    "        if '@' in text:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test of all uids in marc file match a pdf on U drive\n",
    "# short answer: they all do\n",
    "\n",
    "pdf_not_on_U = list()\n",
    "\n",
    "for record in to_do_records:\n",
    "    uid = lookup_uid(record)\n",
    "    if os.path.isfile('source_data/Image_Discs_and_Supplement_Files/{}.pdf'.format(uid)):\n",
    "        continue\n",
    "    pdf_not_on_U.append(uid)\n",
    "\n",
    "print(pdf_not_on_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test of all uids in marc file match a pdf on U drive\n",
    "# short answer: they all do\n",
    "\n",
    "# pdf_not_on_U = list()\n",
    "\n",
    "# for record in marc_images_records:\n",
    "#     uid = lookup_uid(record)\n",
    "#     if os.path.isfile('/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/source_data/Image Discs and Supplement Files/{}.pdf'.format(uid)):\n",
    "#         continue\n",
    "#     pdf_not_on_U.append(uid)\n",
    "\n",
    "# print(pdf_not_on_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "counting_items = dict()\n",
    "\n",
    "def add_to_if_not_yet(k, v):\n",
    "    v = v.strip()\n",
    "    if v == \"None\" or not v or v == None:\n",
    "        return\n",
    "    if k in counting_items:\n",
    "        counting_items[k].add(v)\n",
    "    else:\n",
    "        counting_items[k] = set()\n",
    "        counting_items[k].add(v)\n",
    "\n",
    "for record_as_marc in to_do_records:\n",
    "    record = record_as_marc.as_dict()\n",
    "    if not record['fields']:\n",
    "        break\n",
    "    for dictionary in record['fields']:\n",
    "        for k, v in dictionary.items():\n",
    "            if isinstance(v, str) and v:\n",
    "                add_to_if_not_yet(k, v)\n",
    "            if isinstance(v, dict) and v:\n",
    "                ind1 = v['ind1']\n",
    "                fullpath = '{}/ind1'.format(k)\n",
    "                add_to_if_not_yet(fullpath, ind1)\n",
    "                ind2 = v['ind2']\n",
    "                fullpath = '{}/ind2'.format(k)\n",
    "                add_to_if_not_yet(fullpath, ind2)\n",
    "                subfields = v['subfields']\n",
    "                for subdictionary in subfields:\n",
    "                    for x, y in subdictionary.items():\n",
    "                        fullpath = '{}/subfields/{}'.format(k, x)\n",
    "                        add_to_if_not_yet(fullpath, y)\n",
    "                        \n",
    "for k, v in sorted(counting_items.items()):\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "keys_lengths = dict()\n",
    "all_unique_keys = dict()\n",
    "\n",
    "def add_to_if_not_yet(dictionary, k, v):\n",
    "    if k in dictionary:\n",
    "        dictionary[k].add(v)\n",
    "    else:\n",
    "        dictionary[k] = set()\n",
    "        dictionary[k].add(v)\n",
    "\n",
    "for record_as_marc in to_do_records:\n",
    "    record = record_as_marc.as_dict()\n",
    "    if not record['fields']:\n",
    "        break        \n",
    "    field_keys = {k for field in record['fields'] for k in field.keys()}\n",
    "    fields_list = [k for field in record['fields'] for k in field.keys()]\n",
    "    for unique_field in field_keys:\n",
    "        add_to_if_not_yet(keys_lengths, unique_field, fields_list.count(unique_field))\n",
    "        \n",
    "for record in to_do_records:\n",
    "    for field in record.get_fields():\n",
    "        add_to_if_not_yet(all_unique_keys, field.tag, field.value())\n",
    "\n",
    "print('this (key) shows up {times} in a record:\\n', sorted(keys_lengths.items()))\n",
    "\n",
    "print('\\nthis (key) has {unique values} across the repo:')\n",
    "for k, v in sorted(all_unique_keys.items()):\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_unique_keys['020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is supposed to check for broken utf-8, but i don't trust it's working\n",
    "\n",
    "longest_field = 0\n",
    "\n",
    "for record_as_marc in to_do_records:\n",
    "    for field in record_as_marc.get_fields():\n",
    "        value = field.value()\n",
    "        try:\n",
    "            bytes_value = value.encode()\n",
    "            ascii_value = bytes_value.decode('ascii', \"strict\")\n",
    "            if len(ascii_value) > longest_field:\n",
    "                longest_field = len(ascii_value)\n",
    "                print(record_as_marc)\n",
    "        except:\n",
    "            print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find a record with a certain text in any value\n",
    "\n",
    "for record in marc_unrestricted_records:\n",
    "    for field in record.get_fields():\n",
    "        if 'Jalaluddin' in field.value():\n",
    "            print(lookup_uid(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for record in marc_unrestricted_records:\n",
    "#     if lookup_uid(record) in ('7000228', '7009088', '9609119', '9618339') :\n",
    "#         print(match_degrees(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up SetQ sheets / marc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many in the odd set are already in the Uploaded set?\n",
    "\n",
    "# for file, sheets in all_odds_dict.items():\n",
    "#     if file == 'a':\n",
    "#         for sheet, records in sheets.items():\n",
    "#             for num, record in records.items():\n",
    "#                 if record['PubNames'] in marc_images_uids:\n",
    "#                     # print(record['PubNames'])\n",
    "#                     # no matches\n",
    "#                     pass\n",
    "#     if file == 'c':\n",
    "#         for sheet, records in sheets.items():\n",
    "#             for num, record in records.items():\n",
    "#                 if record['PQ_Number'] not in marc_images_uids:\n",
    "#                     # print(record['PQ_Number'])\n",
    "#                     # no matches\n",
    "#                     pass\n",
    "#     if file == 'b':\n",
    "#         for sheet, records in sheets.items():\n",
    "#             if sheet == 'Digitize from paper':\n",
    "#                 for num, record in records.items():\n",
    "#                     if record['PQ_Dig_Num'] not in marc_images_uids:\n",
    "#                         # print(record['PQ_Dig_Num'])\n",
    "#                         # tons of no matches to uid.\n",
    "#                         pass\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in nnnnnnnn format:   DTLSU_Restrictions_uids\n",
    "#                       DTLSU_from_microfilm_uids\n",
    "#                       PubNum_to_PQNum.keys()\n",
    "\n",
    "# in EPnnnnnn format:   PubNum_to_PQNum.values()\n",
    "#                       MTFC_uids\n",
    "#                       PubNames_uids\n",
    "\n",
    "\n",
    "PubNames_uids = {item['PubNames'] for _, item in all_odds_dict['a']['PubNames'].items()}\n",
    "MTFC_uids = {item['PQ_Number'] for _, item in all_odds_dict['c']['Sheet1'].items()}\n",
    "\n",
    "PubNum_to_PQNum = {item['Pub_Num']: item['PQ_Dig_Num']\n",
    "                   for _, item in all_odds_dict['b']['DigitizeFromPaper'].items()}\n",
    "\n",
    "\n",
    "DTLSU_from_microfilm_uids = {item['Pub_Num']\n",
    "                             for _, item in all_odds_dict['b']['DigitizeFromMicrofilm'].items()}\n",
    "DTLSU_Restrictions_uids = {item['Pub_Num']\n",
    "                           for _, item in all_odds_dict['b']['Restrictions'].items()}\n",
    "\n",
    "\n",
    "print('DTLSU_Restrictions_uids', '\\t\\t',len(DTLSU_Restrictions_uids))\n",
    "print('DTLSU_from_microfilm_uids', '\\t\\t', len(DTLSU_from_microfilm_uids))\n",
    "print('PubNum_to_PQNum.keys()', '\\t\\t\\t', len(PubNum_to_PQNum.keys()))\n",
    "print('PubNum_to_PQNum.values()', '\\t\\t', len(set(PubNum_to_PQNum.values())))\n",
    "print('MTFC_uids', '\\t\\t\\t\\t', len(MTFC_uids))\n",
    "print('PubNames_uids', '\\t\\t\\t\\t', len(PubNames_uids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_set_Q_nnnnn = DTLSU_Restrictions_uids.union(DTLSU_from_microfilm_uids, PubNum_to_PQNum.keys())\n",
    "all_set_Q_EPnnn = PubNames_uids.union(PubNum_to_PQNum.values())\n",
    "all_set_Q_EPnnn.remove(None)\n",
    "\n",
    "print(len(all_set_Q_nnnnn))\n",
    "print(len(all_set_Q_EPnnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_PubNum_to_PQNum = {k: v for k, v in PubNum_to_PQNum.items()\n",
    "                         if v}\n",
    "evil_PubNum_to_PQNum = {k: v for k, v in PubNum_to_PQNum.items()\n",
    "                        if v not in set(clean_PubNum_to_PQNum.values())}\n",
    "\n",
    "print(len(clean_PubNum_to_PQNum))\n",
    "print(len(evil_PubNum_to_PQNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EPnnnnn format  answer:  unexplained overlap\n",
    "\n",
    "print(len(PubNames_uids.intersection(MTFC_uids)))                     #40  all match\n",
    "print(len(PubNames_uids.intersection(PubNum_to_PQNum.values())))      #401 differences everywhere\n",
    "print(len(MTFC_uids.intersection(PubNum_to_PQNum.values())))          #0   none\n",
    "print(set(clean_PubNum_to_PQNum.values()).difference(PubNames_uids))  # that one ?weird? item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nnnnnnn format  -- answer:  all unique\n",
    "\n",
    "print(len(DTLSU_Restrictions_uids.intersection(DTLSU_from_microfilm_uids)))           #0\n",
    "print(len(DTLSU_Restrictions_uids.intersection(PubNum_to_PQNum.keys())))              #0\n",
    "print(len(DTLSU_from_microfilm_uids.intersection(PubNum_to_PQNum.keys())))            #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overlap of setQ's marc record and the excel files' EPnnn format\n",
    "\n",
    "print(len(marc_images_uids))                                         # 441 is good\n",
    "print(len(all_set_Q_EPnnn))                                          # 441 + 1 weird\n",
    "print(len(all_set_Q_EPnnn.intersection(marc_images_uids)))           # 441 is good result\n",
    "print(all_set_Q_EPnnn.symmetric_difference(marc_images_uids))        # one weird item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quat_text(text):\n",
    "    new_text = ''.join(i for i in text if i.isalpha())\n",
    "    return new_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "this_sheetname = 'DigitizeFromMicrofilm'\n",
    "\n",
    "all_odds_titles = set(quat_text(clean_title(v['Title'])) for v in all_odds_dict['b'][this_sheetname].values())\n",
    "marc_all_records_titles = set(quat_text(lookup_clean_title(record)) for record in marc_images_records)\n",
    "\n",
    "intersec = all_odds_titles.intersection(marc_all_records_titles)\n",
    "print(len(all_odds_titles), len(marc_all_records_titles), len(intersec))\n",
    "\n",
    "not_yet_ingested_pub_nums = [int(v['Pub_Num'])\n",
    "                             for v in all_odds_dict['b'][this_sheetname].values()\n",
    "                             if quat_text(clean_title(v['Title'])) not in intersec]\n",
    "\n",
    "already_ingested_pub_nums = [int(v['Pub_Num'])\n",
    "                             for v in all_odds_dict['b'][this_sheetname].values()\n",
    "                             if quat_text(clean_title(v['Title'])) in intersec]\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in all_odds_titles:\n",
    "    if 'anguishedamericaneaster' in i:\n",
    "        print(i)\n",
    "\n",
    "print('***')\n",
    "\n",
    "count = 0\n",
    "for i in marc_all_records_titles:\n",
    "    if 'anguishedamericaneaster' in i:\n",
    "        print(i)\n",
    "        \n",
    "print(len(marc_all_records_titles))\n",
    "print(len(not_yet_ingested_pub_nums))\n",
    "print(len(already_ingested_pub_nums))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exporting the matches & non-matches as csvs\n",
    "\n",
    "list_of_item_dicts = [k for k in all_odds_dict['b'][this_sheetname].values()]\n",
    "records_list = [['Pub_Num', 'Title', 'Author ', 'Subjects', 'Degree_Type', 'Degree_Year', 'Diss_Type', 'School_Name', 'Notes', 0],]\n",
    "for item in list_of_item_dicts:\n",
    "    if quat_text(clean_title(item['Title'])) in intersec:\n",
    "        records_list.append([item[k] for k in records_list[0]])\n",
    "print(records_list)\n",
    "\n",
    "# csv_writer(records_list, '/home/francis/Desktop/{}.csv'.format(this_sheetname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Editing MARC & moving pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pymarc import MARCWriter\n",
    "\n",
    "# trash_file = '/home/francis/Desktop/trash.marc'\n",
    "\n",
    "# # actual_restricted_records = [i for i in orig_restricted_records if lookup_uid(i) not in all_restricteds]\n",
    "# # actual_restricted_records.extend([i for i in orig_unrestricted_records if lookup_uid(i) in restricted_uids])\n",
    "\n",
    "# print(len(expected_unrestricted_records))\n",
    "\n",
    "\n",
    "# with open(trash_file, 'wb') as f:\n",
    "#     for record in expected_unrestricted_records:\n",
    "#         f.write(record.as_marc())\n",
    "    \n",
    "# with open(trash_file, 'rb') as f:\n",
    "#     reader = MARCReader(f)\n",
    "#     trash_records = list()\n",
    "#     for record in reader:\n",
    "#         trash_records.append(record)\n",
    "#     print(len(trash_records), len(expected_unrestricted_records))\n",
    "\n",
    "# print(expected_unrestricted_records[0].as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for uid in folder_duplicated:\n",
    "#     source = os.path.join(folder_on_U, 'UnrestrictedTheses', '{}.pdf'.format(uid))\n",
    "#     dest = os.path.join(folder_on_U, 'TitlesDuplicatedInETDDatbase', '{}.pdf'.format(uid))\n",
    "#     if os.path.isfile(source):\n",
    "#         print(source, '\\n', dest)\n",
    "#         shutil.move(source, dest)\n",
    "\n",
    "        \n",
    "# for uid in folder_true_restrict:\n",
    "#     source = os.path.join(folder_on_U, 'UnrestrictedTheses', '{}.pdf'.format(uid))\n",
    "#     dest = os.path.join(folder_on_U, 'RestrictedTheses', '{}.pdf'.format(uid))\n",
    "#     if os.path.isfile(source):\n",
    "#         print(source, '\\n', dest)\n",
    "#         shutil.move(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set_a = set()\n",
    "# for record in marc_unrestricted_records:\n",
    "#     set_a.add(match_degrees(record)[-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for item in marc_images_records:\n",
    "#     uid = lookup_uid(item)\n",
    "#     if uid in marc_unrestricted_uids:\n",
    "#         print(\"{}: dupe in unrestricted\".format(uid))\n",
    "#     if uid in marc_restricted_uids:\n",
    "#         print(\"{}: dupe in restricted\".format(uid))\n",
    "#     else:\n",
    "#         print('{}: not found dupe'.format(uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for item in marc_images_records:\n",
    "#     for k,v in item.as_dict().items():\n",
    "#         print(k, v)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starting_title = \"\"\"Syntheses and properties of isoporphyrins and related derivatives for application in photodynamic therapy\"\"\"\n",
    "final_title = \"\"\"Synthesis and Properties of Isoporphyrins and Related Derivatives for Application in Photodynamic Therapy\"\"\"\n",
    "\n",
    "print(quat_text(starting_title) == quat_text(final_title))\n",
    "print(quat_text(starting_title))\n",
    "print(quat_text(final_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "existing_dept_full = dict()\n",
    "for row, value in all_odds_dict['d']['Department Codes'].items():\n",
    "    if existing_dept_full.get(value['DEPT']):\n",
    "        print('oops')\n",
    "    existing_dept_full[value['DEPT']] = value['department']\n",
    "    \n",
    "print(len(existing_dept_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row, value in all_odds_dict['d']['Sheet1'].items():\n",
    "    if not existing_dept_full.get(value['DEPT']):\n",
    "        print(value['DEPT'])\n",
    "existing_dept_full['MRSC'] = 'MRSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for update_row, update_value in all_odds_dict['e']['Sheet1'].items():\n",
    "    match = False\n",
    "    for original_row, original_value in all_odds_dict['f']['8734465'].items():\n",
    "        if update_value['author1_lname'] == original_value['author1_lname'] and \\\n",
    "            update_value['author1_mname'] == original_value['author1_mname'] and \\\n",
    "            update_value['author1_fname'] == original_value['author1_fname']:\n",
    "                if existing_dept_full[update_value['DEPT']] != original_value['department']:\n",
    "                    print(original_value['title'])\n",
    "                    print(existing_dept_full[update_value['DEPT']])\n",
    "                    print(original_value['department'])\n",
    "                    print(original_value['legacy_department'])\n",
    "                    print('\\n')\n",
    "                match = True\n",
    "    if not match:\n",
    "            print(update_value['author1_fname'], update_value['author1_mname'], update_value['author1_lname'])\n",
    "#             print(original_value['author1_fname'], original_value['author1_mname'], original_value['author1_lname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
